plot(x, y, main="Boiling Point vs Pressure", xlab="Barometric Pressure",
ylab="Boiling Point (Farenheit)")
model = lm(y~x)
summary(model)
confint(model, level = .9)
ybar = mean(temp)
ybar = mean(y)
Syy = sum((y - ybar)^2)
Syy
ybar
beta1 = summary(model)$coef[2,1]
xbar = mean(x)
Sxx = sum((x - xbar)^2)
SSR = (beta1^2)*(Sxx)
SSR
SSE = SST - SSR
SST = Syy
SSE = SST - SSR
SSE
pressure = c(20.79, 20.79, 22.40, 22.67, 23.15, 23.35, 23.89, 23.99, 24.02, 24.01,
25.14, 26.57, 28.49, 27.76, 29.04, 29.88, 30.06)
temp = c(194.5, 194.3, 197.9, 198.4, 199.4, 199.9, 200.9, 201.1, 201.4, 201.3,
203.6, 204.6, 209.5, 208.6, 210.7, 211.9, 212.2)
plot(pressure, temp, main = "Boiling Point by Barometric Pressure",
xlab="Barometric Pressure (inches of mercury)",
ylab="Boiling Point (Farenheit)")
model = lm(temp~pressure)
abline(model, col = "blue")
summary(model)
confint(model, level = .9)
xbar = mean(pressure)
ybar = mean(temp)
beta1 = summary(model)$coef[2,1]
Syy = sum((temp - ybar)^2)
Sxx = sum((pressure - xbar)^2)
SST = Syy
SST
SSR = (beta1^2)*(Sxx)
SSR
SSE = SST - SSR
SSE
rm(list = ls())
year = c(1924, 1928, 1932, 1936, 1948, 1952, 1956, 1960, 1964, 1968, 1972, 1976,
1980, 1984, 1988, 1992)
time = c(83.2, 82.2, 79.4, 78.9, 74.4, 74.3, 72.9, 69.3, 67.7, 66.2, 68.8, 61.8,
60.9, 62.6, 60.9, 60.7)
plot(year, time, main="Olympic 100 meter backstroke winning times",
xlab="Year", ylab="Time")
model = lm(time~year)
abline(model, col = "blue")
summary(model)
confint(model, level = .99)
ybar = mean(time)
xbar = mean(year)
Sxx = sum((year - xbar)^2)
Sxx
Sxy = sum((year - xbar)*(time - ybar))
Sxy
Syy = sum((time - ybar)^2)
Syy
-0.35413 (2140)
-0.35413 * (2140) + 764.35625
MSE = c(50, 40, 35, 25, 35, 25, 30, 25)
1 - MSE/950
detach()
attach()
rm(list = ls())
help
load("~/.RData")
rm(list=ls())
sample <- c(121, 98, 95, 94, 102, 106, 112, 120, 108, 109)
x.bar <- mean(sample)
n <- length(sample)
s <- sd(sample)
z.score <- (x.bar - mu0)
z.score <- (x.bar - mu0)
mu0 <- 100
z.score <- (x.bar - mu0) / (s/sqrt(n))
z.alpha <- qnorm(alpha)
alpha = 0.05
z.alpha <- qnorm(alpha)
z.alpha <- qnorm(1-alpha)
p.value <- pnorm(z.score)
p.value <- 1-pnorm(z.score)
# Rejection Region
RR <- (z.alpha*s/sqrt(n)) + mu0
rm(list=ls())
sample <- c(121, 98, 95, 94, 102, 106, 112, 120, 108, 109)
# Null Hypothesis: Sample mean is equal to population mean of 100
# Alternative Hypothesis: Sample mean is greater than population mean
mu0 <- 100
alpha = 0.05
n <- length(sample)
x.bar <- mean(sample)
s <- 10
z.score <- (x.bar - mu0) / (s/sqrt(n))
p.value <- 1-pnorm(z.score)
z.alpha <- qnorm(1-alpha)
# Rejection Region
RR <- (z.alpha*s/sqrt(n)) + mu0
sigma <- 10
sum((sample - x.bar)^2)
sum((sample - x.bar)^2) / (n-1)
#---------------------------------------------------------
# Conclusion: Because our test statistic > critical value, we reject the null
#   hypothesis and conclude that the special training significantly improved
#   the IQ scores of the sample population. Based on our rejection region, we
#   would reject any sample mean greater than 105.20 when alpha = 0.05
#---------------------------------------------------------
# Part 2: What if the variance was unknown?
#
# I would perform the same z-test, but I would calculate the standard deviation
# of the sample and use this as an estimate
rm(list=ls())
sample <- c(121, 98, 95, 94, 102, 106, 112, 120, 108, 109)
# Null Hypothesis: Sample mean is equal to population mean of 100
# Alternative Hypothesis: Sample mean is greater than population mean
mu0 <- 100
alpha = 0.05
n <- length(sample)
x.bar <- mean(sample)
sample.s.squared = sum((sample - x.bar)^2) / (n-1)
sample.SD = sqrt(sample.s.squared)
z.score <- (x.bar - mu0) / (sigma/sqrt(n))
p.value <- 1-pnorm(z.score)
#---------------------------------------------------------
# Conclusion: Because our test statistic > critical value, we reject the null
#   hypothesis and conclude that the special training significantly improved
#   the IQ scores of the sample population. Based on our rejection region, we
#   would reject any sample mean greater than 105.20 when alpha = 0.05
#---------------------------------------------------------
# Part 2: What if the variance was unknown?
#
# I would perform the same z-test, but I would calculate the standard deviation
# of the sample and use this as an estimate
rm(list=ls())
sample <- c(121, 98, 95, 94, 102, 106, 112, 120, 108, 109)
# Null Hypothesis: Sample mean is equal to population mean of 100
# Alternative Hypothesis: Sample mean is greater than population mean
mu0 <- 100
alpha = 0.05
n <- length(sample)
x.bar <- mean(sample)
sample.s.squared = sum((sample - x.bar)^2) / (n-1)
sample.SD = sqrt(sample.s.squared)
z.score <- (x.bar - mu0) / (sample.SD/sqrt(n))
p.value <- 1-pnorm(z.score)
z.alpha <- qnorm(1-alpha)
# Rejection Region
RR <- (z.alpha*sample.SD/sqrt(n)) + mu0
#----------------------------------------------------
# Calc 95% CI for mu
xbar <- mean(sample)
xbar
mu
mu <- 100
s <- SD(sample)
s <- sample.SD
z.critical <- pnorm(.95)
z.critical <- pnorm(.95/2)
z.critical <- pnorm(.05/2)
z.critical <- qnorm(.05/2)
z.critical <- qnorm(1-alpha)
z.critical <- qnorm(1-alpha/2)
CI <- z.critical * [(xbar - mu) / (s/sqrt(n))]
CI <- z.critical * ((xbar - mu) / (s/sqrt(n)))
pnorm(-1.0739)
pnorm(1.957)
1-ans
1-pnorm(1.957)
vec <- c(21.3 28.8 17.6 23.0 27.2 28.5 32.8 28.2 25.9 22.5 27.2 33.1 28.7 24.8 24.3
vec <- c(21.3, 28.8, 17.6, 23.0, 27.2, 28.5, 32.8, 28.2, 25.9, 22.5, 27.2, 33.1, 28.7, 24.8, 24.3,
27.1, 30.6, 26.8, 18.9, 36.3, 28.0, 17.9, 25.0, 27.5, 27.7, 32.1, 28.0, 30.9, 20.0, 20.2,
33.5, 26.4, 30.9, 33.2)
vec
vec[order(vec)]
ordered.vec <- vec[order(vec)]
ordered.vec[12]
ordered.vec[23]
rm(list=ls())
data <- c(21, 18, 42, 29, 81, 12, 94, 117, 88, 210,
44, 39, 11, 83, 42, 94, 2, 11, 33, 91,
141, 48, 12, 50, 61, 35, 111, 73, 5, 44,
6, 11, 35, 91, 147, 83, 91, 48, 22, 17)
data[data > 50]
n.minus <- data[data < 50]
n.plus <- data[data > 50]
n.minus <- data[data < 50]
data[data > 50]
n.plus.length()
length(n.plus)
n.plus.vector <- data[data > 50]
n.plus <- length(n.plus.vector)
n.minus <- length(n.minus.vector)
n.minus.vector <- data[data < 50]
n.minus <- length(n.minus.vector)
rm(list=ls())
data <- c(21, 18, 42, 29, 81, 12, 94, 117, 88, 210,
44, 39, 11, 83, 42, 94, 2, 11, 33, 91,
141, 48, 12, 50, 61, 35, 111, 73, 5, 44,
6, 11, 35, 91, 147, 83, 91, 48, 22, 17)
n.plus.vector <- data[data > 50]
n.plus <- length(n.plus.vector)
n.minus.vector <- data[data < 50]
n.minus <- length(n.minus.vector)
wilcox.test(data, alternative = "two.sided", mu=50)
wilcox.test(data, alternative = "two.sided", mu=51)
data <- c(21, 18, 42, 29, 81, 12, 94, 117, 88, 210,
44, 39, 11, 83, 42, 94, 2, 11, 33, 91,
141, 48, 12, 50, 61, 35, 111, 73, 5,
6, 11, 35, 91, 147, 83, 91, 48, 22, 17)
wilcox.test(data, alternative = "two.sided", mu=51)
rm(list=ls())
data <- c(21, 18, 42, 29, 81, 12, 94, 117, 88, 210,
44, 39, 11, 83, 42, 94, 2, 11, 33, 91,
141, 48, 12, 50, 61, 35, 111, 73, 5, 44,
6, 11, 35, 91, 147, 83, 91, 48, 22, 17)
n.plus.vector <- data[data > 50]
n.plus <- length(n.plus.vector)
n.minus.vector <- data[data < 50]
n.minus <- length(n.minus.vector)
wilcox.test(data, alternative = "two.sided", mu=51)
data <- data[data != 50]
length(data)
data
data <- data[data != 50]
wilcox.test(data, alternative = "two.sided", mu=50, paired=TRUE)
wilcox.test(data, y = NULL, alternative = "two.sided", mu=50, paired=TRUE)
wilcox.test(data, alternative = "two.sided", mu=50, exact=FALSE)
# Manually perform the Wilcox signed-rank test
difference <- data - 50
difference
z.values <- ifelse(difference > 0, 1, 0)
z.values
length(z.values)
differece * z.values
difference * z.values
sum(difference * z.values)
absolute.difference <- abs(difference)
absolute.difference
r.values <- rank(absolute.difference)
r.values
S.plus <- sum(r.values * z.values)
39*40/2
# Generate data using built-in functions
x <- 1:10
y <- rnorm(10)
# Create a data frame from generated data
data <- data.frame(X = x, Y = y)
# Display the generated data frame
print(data)
df <- data.frame(x - theta = difference, |x - theta| = absolute.difference)
df <- data.frame(x = difference, y = absolute.difference)
df <- data.frame("x" = difference, y = absolute.difference)
df
df <- data.frame("x - theta" = difference, y = absolute.difference)
df
df <- data.frame("x"=data, "x-theta"=difference, "|x-theta|"= absolute.difference)
df <- data.frame("x-theta"=difference, "|x-theta|"= absolute.difference)
# I chose to solve issue 1 by removing the value of 50 from my data vector
# For issue two, when a tie occurs in the data, I will assign the median rank
#    value based on
data <- data[data != 50]
df <- data.frame("x"=data, "x-theta"=difference, "|x-theta|"= absolute.difference)
data
data <- c(21, 18, 42, 29, 81, 12, 94, 117, 88, 210,
44, 39, 11, 83, 42, 94, 2, 11, 33, 91,
141, 48, 12, 50, 61, 35, 111, 73, 5, 44,
6, 11, 35, 91, 147, 83, 91, 48, 22, 17)
# I chose to solve issue 1 by removing the value of 50 from my data vector
# For issue two, when a tie occurs in the data, I will assign the median rank
#    value based on
data <- data[data != 50]
rm(list=ls())
data <- c(21, 18, 42, 29, 81, 12, 94, 117, 88, 210,
44, 39, 11, 83, 42, 94, 2, 11, 33, 91,
141, 48, 12, 50, 61, 35, 111, 73, 5, 44,
6, 11, 35, 91, 147, 83, 91, 48, 22, 17)
n.plus.vector <- data[data > 50]
n.plus <- length(n.plus.vector)
n.minus.vector <- data[data < 50]
n.minus <- length(n.minus.vector)
wilcox.test(data, alternative = "two.sided", mu=50)
# I chose to solve issue 1 by removing the value of 50 from my data vector
# For issue two, when a tie occurs in the data, I will assign the median rank
#    value based on
data <- data[data != 50]
# Manually perform the Wilcox signed-rank test
difference <- data - 50
absolute.difference <- abs(difference)
r.values <- rank(absolute.difference)
z.values <- ifelse(difference > 0, 1, 0)
S.plus <- sum(r.values * z.values)
df <- data.frame("x"=data, "x-theta"=difference, "|x-theta|"= absolute.difference)
df
df <- data.frame("x"=data, "x-theta"=difference, "abs(x-theta)"= absolute.difference)
df
df <- data.frame("x"=data, "x-theta"=difference, "abs(x-theta)"= absolute.difference
"r values"=r.values, "z values"=z.values)
df <- data.frame("x"=data, "x-theta"=difference, "abs(x-theta)"= absolute.difference,
"r values"=r.values, "z values"=z.values)
df
# ----------------
# Make a histogram of the data to check if the symmetry assumption for our
# data looks reasonable
hist(data, main = "Checking for Symmetry", xlab = "Number of Diseased Plants",
ylab = "Frequency")
pt(-.0639, 4)
pt(-.0639, 4)
wilcox.test(9)
x <- c(10, 15, 19)
y <- c(12, 17, 50)
wilcox.test(x, y mu = 0)
wilcox.test(x, y, mu = 0)
# Problem 1
x <- c(10, 15, 19)
y <- c(12, 17, 50)
wilcox.test(x, y, paired = TRUE,
alternative = "lesser")
wilcox.test(x, y, paired = TRUE, alternative = "lesser")
wilcox.test(x, y, paired = TRUE, alternative = "less")
clear
wilcox.test(x, y, paired = TRUE, alternative = "less")
wilcox.test(x, y, paired = FALSE, alternative = "less")
wilcox.test(x, y, alternative = "less")
# Problem 2
x <- c(21, 20, 17, 25, 29, 21, 32, 18, 32, 31)
y <- c(45, 14, 13, 31, 35, 20, 58, 41, 64, 25)
wilcox.test(x, y, alternative = "less")
# Problem 3
x <- c(5, 11, 16, 8, 12)
y <- c(17, 14, 15, 21, 19, 13)
wilcox.test(x, y, alternative = "less")
# Problem 4
x <- c(91, 61, 24, 24)
y <- c(87, 49, 32, 32)
wilcox.test(x, y, alternative = "less")
wilcox.test(x, y, alternative = "less")
# Problem 1
x <- c(10, 15, 19)
y <- c(12, 17, 50)
wilcox.test(x, y, alternative = "less")
# Problem 2
x <- c(21, 20, 17, 25, 29, 21, 32, 18, 32, 31)
y <- c(45, 14, 13, 31, 35, 20, 58, 41, 64, 25)
wilcox.test(x, y, alternative = "two.sided")
# Problem 3
x <- c(5, 11, 16, 8, 12)
y <- c(17, 14, 15, 21, 19, 13)
wilcox.test(x, y, alternative = "less")
wilcox.test(x, y, alternative = "two.sided")
# Problem 4
x <- c(91, 61, 24, 24)
y <- c(87, 49, 32, 32)
wilcox.test(x, y, alternative = "less")
wilcox.test(x, y, alternative = "two.sided")
x <- c(-24, 6, 4, -6, -6, 1, -26, -23, -32, 6)
1+4+10.5+19.5+15.5+10+7+6+3+2
10*11/2
20*21/2
5+8+10.5+15.5+15.5+19.5+18+15.5+12+12
131.5+78.5
10*10+10*11/2-78.5
10*10+10*11/2-131.5
diabetic <- c(42, 44, 38, 52, 48, 46, 34, 44, 38)
normal <- c(34, 43, 35, 33, 34, 26, 30, 31, 27, 28, 27,
30, 37, 38, 32, 32, 36, 32, 32, 38, 42, 36, 44, 3, 38)
wmwTest(diabetic)
wilcox.test(diabetic)
wilcox.test(diabetic, normal)
wilcox.test(diabetic, normal, exact = FALSE)
wilcox.test(diabetic, normal, alternative ="two.sided", exact = FALSE)
diabetic <- c(42, 44, 38, 52, 48, 46, 34, 44, 38)
normal <- c(34, 43, 35, 33, 34, 26, 30, 31, 27, 28, 27,
30, 37, 38, 32, 32, 36, 32, 32, 38, 42, 36, 44, 3, 38)
wilcox.test(diabetic, normal, alternative ="two.sided", exact = FALSE)
wilcox.test(normal, diabetic, alternative ="two.sided", exact = FALSE)
n = diabetic.length
n = length(diabetic)
m = length(normal)
nm + n(n+1)/2 -201.5
n*m + n(n+1)/2 -201.5
n*m + n*(n+1)/2 -201.5
n*m + m*(m+1)/2 - 23.5
n*m-68.5
n*m
n*m -201.5
n*m
225-68.5
m
m*(m+1)/2
diabetic <- c(42, 44, 38, 52, 48, 46, 34, 44, 38)
normal <- c(34, 43, 35, 33, 34, 26, 30, 31, 27, 28, 27,
30, 37, 38, 32, 32, 36, 32, 32, 38, 42, 36, 44, 3, 38)
n = length(diabetic)
m = length(normal)
wilcox.test(normal, diabetic, alternative ="two.sided", exact = FALSE)
wilcox.test(normal, diabetic, alternative ="two.sided", exact = FALSE ,conf.int = TRUE)
rural <- c(3, 2, 1, 1, 2, 1, 3, 2, 2, 2, 2, 5, 1, 4, 1, 1, 1, 1, 6, 2, 2, 1, 1)
urban <- c(1, 0, 1, 1, 0, 0, 1, 1, 1, 8, 1, 1, 1, 0, 1, 1, 2)
wilcox.test(rural, urban)
wilcox.test(rural, urban, exact = FALSE)
wilcox.test(urban, rural, exact = FALSE)
wilcox.test(urban, rural, alternative ="two.sided", exact = FALSE)
diabetic <- c(42, 44, 38, 52, 48, 46, 34, 44, 38)
normal <- c(34, 43, 35, 33, 34, 26, 30, 31, 27, 28, 27,
30, 37, 38, 32, 32, 36, 32, 32, 38, 42, 36, 44, 3, 38)
wilcox.test(normal, diabetic, alternative ="two.sided", exact = FALSE ,conf.int = TRUE, conf.level = 0.95)
t.test(normal, diabetic)
t.test(normal, diabetic, alternative = "two.sided")
t.test(normal, diabetic, alternative = "two.sided")
wilcox.test(normal, diabetic, alternative ="two.sided", exact = FALSE ,conf.int = TRUE, conf.level = 0.95)
siegel.test(x,y)
siegelTukey(x,y)
install.packages("lawstat")
library(lawstat)
siegelTukey(x,y)
siegel.test(x,y)
x <- c(21.9, 20.3, 19.4, 20.4, 19.6, 20.5, 18.4, 20.1, 22, 18.9)
y <- c(20.2, 13.8, 21.8, 19.2, 19.7, 25.5, 17, 17.6, 19.5, 22.2)
rm(list=ls())
A = c(-.1, 1.5, -.6, -1.4,
-1.2, -0.5, 1.0, -1.5,
0.1, 0.5, -0.5, -2.0)
A = matrix(A, nrow=3, byrow=TRUE)
t(A)
B = A %*% t(A)
C = t(A) %*% A
install.packages("MASS")
library(MASS)
solve(B)
B = A %*% t(A)
C = t(A) %*% A
B
C
solve(B)
ginv(B)
solve(C)
ginv(C)
row.median = apply(A, 1, median)
column.std = apply(A, 2, sd)
row.median
column.std
# 3c
sleep17 = data[,1:7]
apply(na.omit(sleep17), 2, mean) # ignoring nan
apply(sleep17, 2, mean) # including nan
data <- read.table("sleep.txt", header=T)
y <- data$NonD
getwd()
setwd("C:/J/Computational-Statistics/HW1")
ls
data <- read.table("sleep.txt", header=T)
y <- data$NonD
length(y)
sum(!is.na(y))
# 3b
w = na.omit(y)
w = y[!is.na(y)]
# 3c
sleep17 = data[,1:7]
apply(na.omit(sleep17), 2, mean) # ignoring nan
apply(sleep17, 2, mean) # including nan
# 3d
sleep35 = data[,3:5]
boxplot(sleep35, main = "Box Plot of the Sleep Data")
# 3e
tapply(data$Sleep, data$Danger, mean, na.rm = T)
# 4a
sumdice <- function(n) {
dice = runif(n)
return(sum(dice))
}
sumdice(1)
sumdice <- function(n) {
dice = runif(n)
print(dice)
return(sum(dice))
}
sumdice(1)
?runif
sumdice <- function(n) {
dice = sample(1:6, n, replace=TRUE)
print(dice)
return(sum(dice))
}
sumdice(1)
sumdice(2)
sumdice(10)
?sample
# 4a
v <- sample(1:6, 10000*100, replace=TRUE)
rm(list=ls())
# 4a
v <- sample(1:6, 10000*100, replace=TRUE)
?matrix
# 4b
vmat <- matrix(v, nrow=10000, ncol=100)
# 4c
rowSums(vmat)
# 4d
mean(row.sum)
# 4c
row.sum <- rowSums(vmat)
# 4d
mean(row.sum)
var(row.sum)
# 4e
hist(row.sum, freq=F, breaks="Scott", main="Histogram of X")
?hist
# 4e
hist(row.sum, freq=F, breaks="Scott", main="Histogram of X", xlab="sum")
